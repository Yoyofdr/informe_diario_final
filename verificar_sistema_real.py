#!/usr/bin/env python
"""
Verificaci√≥n real del sistema de informes con los archivos correctos
"""

import os
import sys
import django
from datetime import datetime, timedelta

# Configurar Django
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'market_sniper.settings')
django.setup()

from django.utils import timezone
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

print("\n" + "="*70)
print("üîç VERIFICACI√ìN COMPLETA DEL SISTEMA DE INFORMES")
print(f"üìÖ Fecha: {datetime.now().strftime('%d/%m/%Y %H:%M')}")
print("="*70)

# 1. VERIFICAR SCRAPERS
print("\nüìä 1. VERIFICANDO SCRAPERS...")
print("-"*70)

scrapers_status = {}

# Scrapers CMF y DT (principales)
try:
    from scripts.scrapers.scraper_cmf_mejorado import obtener_documentos_cmf_con_contenido
    documentos = obtener_documentos_cmf_con_contenido(dias_atras=1)
    if documentos:
        scrapers_status["CMF"] = len(documentos)
        print(f"‚úÖ CMF: {len(documentos)} documentos")
    else:
        scrapers_status["CMF"] = 0
        print("‚ö†Ô∏è CMF: Sin documentos recientes")
except Exception as e:
    scrapers_status["CMF"] = -1
    print(f"‚ùå CMF: Error - {str(e)[:50]}")

try:
    from scripts.scrapers.scraper_dt import ScraperDiarioOficial
    scraper = ScraperDiarioOficial()
    publicaciones = scraper.obtener_publicaciones(dias_atras=1)
    if publicaciones:
        scrapers_status["Diario Oficial"] = len(publicaciones)
        print(f"‚úÖ Diario Oficial: {len(publicaciones)} publicaciones")
    else:
        scrapers_status["Diario Oficial"] = 0
        print("‚ö†Ô∏è Diario Oficial: Sin publicaciones recientes")
except Exception as e:
    scrapers_status["Diario Oficial"] = -1
    print(f"‚ùå Diario Oficial: Error - {str(e)[:50]}")

# Medio Ambiente (SEA/SMA)
try:
    from scripts.scrapers.scraper_ambiental_integrado import ScraperAmbiental
    scraper = ScraperAmbiental()
    datos = scraper.obtener_datos_ambientales(dias_atras=7)
    total = len(datos.get('proyectos_sea', [])) + len(datos.get('sanciones_sma', []))
    scrapers_status["Medio Ambiente"] = total
    print(f"‚úÖ Medio Ambiente: {len(datos.get('proyectos_sea', []))} SEA, {len(datos.get('sanciones_sma', []))} SMA")
except Exception as e:
    scrapers_status["Medio Ambiente"] = -1
    print(f"‚ùå Medio Ambiente: Error - {str(e)[:50]}")

# Proyectos de Ley
try:
    from scripts.scrapers.scraper_proyectos_ley_integrado import ScraperProyectosLeyIntegrado
    scraper = ScraperProyectosLeyIntegrado()
    proyectos = scraper.obtener_todos_los_proyectos(dias_atras=7)
    scrapers_status["Proyectos de Ley"] = len(proyectos)
    print(f"‚úÖ Proyectos de Ley: {len(proyectos)} proyectos")
except Exception as e:
    scrapers_status["Proyectos de Ley"] = -1
    print(f"‚ùå Proyectos de Ley: Error - {str(e)[:50]}")

# Reglamentos (Contralor√≠a)
try:
    from scripts.scrapers.scraper_contraloria_reglamentos import ScraperContraloria
    scraper = ScraperContraloria()
    reglamentos = scraper.obtener_reglamentos_recientes(dias_atras=7)
    scrapers_status["Reglamentos"] = len(reglamentos)
    print(f"‚úÖ Reglamentos: {len(reglamentos)} reglamentos")
except Exception as e:
    scrapers_status["Reglamentos"] = -1
    print(f"‚ùå Reglamentos: Error - {str(e)[:50]}")

# 2. VERIFICAR GENERACI√ìN DE INFORME
print("\nüìù 2. VERIFICANDO GENERACI√ìN DE INFORME...")
print("-"*70)

try:
    from scripts.generators.generar_informe_oficial_integrado_mejorado import generar_informe_completo
    
    # Simular generaci√≥n de informe
    print("Generando informe de prueba (sin enviar)...")
    contenido = generar_informe_completo(test_mode=True)
    
    if contenido:
        print("‚úÖ Informe generado correctamente")
        
        # Verificar secciones
        secciones_esperadas = [
            "RESUMEN EJECUTIVO",
            "COMISI√ìN PARA EL MERCADO FINANCIERO",
            "DIARIO OFICIAL",
            "MEDIO AMBIENTE",
            "PROYECTOS DE LEY", 
            "REGLAMENTOS"
        ]
        
        print("\nSecciones del informe:")
        for seccion in secciones_esperadas:
            if seccion in contenido:
                print(f"  ‚úÖ {seccion}")
            else:
                print(f"  ‚ö†Ô∏è {seccion} - No encontrada")
    else:
        print("‚ùå No se pudo generar el informe")
        
except Exception as e:
    print(f"‚ùå Error generando informe: {str(e)}")

# 3. VERIFICAR SISTEMA DE ENV√çOS
print("\nüìß 3. VERIFICANDO SISTEMA DE ENV√çOS...")
print("-"*70)

try:
    from alerts.models import Destinatario
    
    # Contar destinatarios
    destinatarios = Destinatario.objects.all()
    total = destinatarios.count()
    
    # Verificar trials
    con_trial = destinatarios.filter(
        es_pagado=False,
        fecha_fin_trial__gte=timezone.now()
    ).count()
    
    pagados = destinatarios.filter(es_pagado=True).count()
    trial_vencido = destinatarios.filter(
        es_pagado=False,
        fecha_fin_trial__lt=timezone.now()
    ).count()
    
    print(f"‚úÖ Total destinatarios: {total}")
    print(f"  - Clientes pagados: {pagados}")
    print(f"  - En per√≠odo de prueba activo: {con_trial}")
    print(f"  - Trial vencido: {trial_vencido}")
    
    # Mostrar pr√≥ximos vencimientos
    proximos_vencer = destinatarios.filter(
        es_pagado=False,
        fecha_fin_trial__gte=timezone.now(),
        fecha_fin_trial__lte=timezone.now() + timedelta(days=3)
    )
    
    if proximos_vencer.exists():
        print("\n‚ö†Ô∏è Trials pr√≥ximos a vencer (3 d√≠as):")
        for dest in proximos_vencer:
            dias_restantes = (dest.fecha_fin_trial - timezone.now()).days
            print(f"  - {dest.email}: {dias_restantes} d√≠as restantes")
    
except Exception as e:
    print(f"‚ùå Error verificando destinatarios: {str(e)}")

# 4. VERIFICAR CONFIGURACI√ìN
print("\n‚öôÔ∏è 4. VERIFICANDO CONFIGURACI√ìN...")
print("-"*70)

# Verificar variables de entorno cr√≠ticas
env_vars = {
    "OPENAI_API_KEY": os.environ.get('OPENAI_API_KEY', ''),
    "EMAIL_HOST_USER": os.environ.get('EMAIL_HOST_USER', ''),
    "EMAIL_HOST_PASSWORD": os.environ.get('EMAIL_HOST_PASSWORD', ''),
}

config_ok = True
for var, value in env_vars.items():
    if value:
        print(f"‚úÖ {var}: Configurado")
    else:
        print(f"‚ùå {var}: NO configurado")
        config_ok = False

# 5. RESUMEN FINAL
print("\n" + "="*70)
print("üìä RESUMEN FINAL DEL SISTEMA")
print("="*70)

# Contar scrapers funcionando
scrapers_ok = sum(1 for v in scrapers_status.values() if v > 0)
scrapers_error = sum(1 for v in scrapers_status.values() if v == -1)
scrapers_sin_datos = sum(1 for v in scrapers_status.values() if v == 0)

print(f"\nüìã Estado de Scrapers:")
print(f"  - Funcionando: {scrapers_ok}/{len(scrapers_status)}")
print(f"  - Sin datos recientes: {scrapers_sin_datos}")
print(f"  - Con errores: {scrapers_error}")

print("\nüìä Detalle por fuente:")
for scraper, count in scrapers_status.items():
    if count > 0:
        print(f"  ‚úÖ {scraper}: {count} items")
    elif count == 0:
        print(f"  ‚ö†Ô∏è {scraper}: Sin datos")
    else:
        print(f"  ‚ùå {scraper}: Error")

# Evaluaci√≥n final
print("\n" + "="*70)
if scrapers_ok >= 3 and config_ok:
    print("‚úÖ SISTEMA OPERATIVO - Listo para env√≠o de informes")
    print("üìå Pr√≥ximo env√≠o: Ma√±ana 9:00 AM (Chile)")
elif scrapers_ok >= 2:
    print("‚ö†Ô∏è SISTEMA PARCIALMENTE OPERATIVO")
    print("   Algunas fuentes no est√°n disponibles")
    print("   Los informes se generar√°n con las fuentes disponibles")
else:
    print("‚ùå SISTEMA CON PROBLEMAS CR√çTICOS")
    print("   Revisar scrapers y configuraci√≥n")

print("="*70)